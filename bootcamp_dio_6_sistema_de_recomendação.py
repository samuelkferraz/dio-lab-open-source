# -*- coding: utf-8 -*-
"""Bootcamp DIO - 6 - Sistema de Recomendação.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qwnYr4JUIL3tcfqH-DyFOEOkdGyXJhI-

# Sistema de Recomendação por imagem

O objetivo desse código é criar um Sistema de Recomendação por imagens que sugira produtos visualmente similares com base em suas características visuais (como cor, formato e textura). O sistema é criado a partir do treinamento de uma rede neural com um dataset imagens de produtos do Kaggle com a rede pré-treinada ResNet.
"""

# Importando um dataset com produtos do Kaggle

import kagglehub

path = kagglehub.dataset_download("paramaggarwal/fashion-product-images-dataset")

print("Path to dataset files:", path)

# Explorando o dataset

import os

# Listar os arquivos baixados
dataset_path = path  # Caminho do dataset
print("Arquivos no dataset:")
print(os.listdir(dataset_path))

# Definir caminho do dataset
dataset_dir = os.path.join(dataset_path, "fashion-dataset")

# Listar arquivos e subpastas dentro do diretório principal
print("Conteúdo da pasta fashion-dataset:")
print(os.listdir(dataset_dir))

# Explorando as imagens

# Caminho das imagens
images_path = os.path.join(dataset_dir, "images")

import random
import matplotlib.pyplot as plt
import cv2

# Selecionar 10 imagens aleatórias para visualizar
sample_images = random.sample(os.listdir(images_path), 10)

# Exibir as imagens
fig, axes = plt.subplots(2, 5, figsize=(15, 6))
for img_file, ax in zip(sample_images, axes.ravel()):
    img = cv2.imread(os.path.join(images_path, img_file))  # Carregar imagem
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Converter de BGR para RGB
    ax.imshow(img)
    ax.set_title(img_file)  # Nome do arquivo
    ax.axis("off")

plt.show()

# Explorando as classes do dataset

import pandas as pd

# Carregar os metadados ignorando erros
styles_path = os.path.join(dataset_dir, "styles.csv")

df = pd.read_csv(styles_path, on_bad_lines="skip", encoding="utf-8")

# Exibir as colunas disponíveis
print("Colunas do dataset:", df.columns)

# Exibir categorias únicas em algumas colunas relevantes
print("\nCategorias disponíveis:")
print("Master Category:\n", df["masterCategory"].unique())
print("\nSub Category:\n", df["subCategory"].unique())
print("\nArticle Type:\n", df["articleType"].unique()) # A princípio, parece ser o mais adequado usar 'articleType' como classe

# Definir as classes escolhidas
selected_classes = ["Tshirts", "Sunglasses", "Caps", "Casual Shoes", "Sports Shoes"]

# Filtrar o dataset apenas com as classes selecionadas
filtered_df = df[df["articleType"].isin(selected_classes)]

# Contar quantas amostras existem para cada classe
print(filtered_df["articleType"].value_counts())

# Estruturando os diretórios e ocupando com 283 imagens de cada classe

import shutil

images_dir = os.path.join(dataset_dir, "images")
output_dir = "/content/dataset"

# Criar Diretórios das classes
classes = ["Tshirts", "Casual Shoes", "Sunglasses", "Caps"]
for class_name in classes:
    os.makedirs(os.path.join(output_dir, class_name), exist_ok=True)

# Filtrar apenas as classes selecionadas e balancear para 283 imagens cada
df_filtered = (
    df[df["articleType"].isin(classes)]
    .groupby("articleType", group_keys=False)
    .apply(lambda x: x.sample(n=283, random_state=42))
    .reset_index(drop=True)
)

# Copiar imagens para o novo diretório
for _, row in df_filtered.iterrows():
    img_filename = f"{row['id']}.jpg"
    src_path = os.path.join(images_dir, img_filename)
    dst_path = os.path.join(output_dir, row["articleType"], img_filename)

    if os.path.exists(src_path):
        shutil.copy(src_path, dst_path)

print("Dataset balanceado criado com sucesso!")

# Carregando a ResNet, processando as imagens e salvando os embenddings

import tensorflow as tf
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing import image
import numpy as np
import os
import pickle
from tqdm import tqdm  # Para visualizar progresso

# Carregar modelo ResNet50 sem a camada de classificação final
resnet_model = ResNet50(weights="imagenet", include_top=False, pooling="avg")

# Diretório das imagens processadas
output_dir = "/content/dataset"

# Dicionário para armazenar os embeddings
embeddings = {}

# Função para extrair features de uma única imagem
def extract_features(img_path, model):
    img = image.load_img(img_path, target_size=(224, 224))  # Redimensiona para 224x224
    img_array = image.img_to_array(img)  # Converte para array NumPy
    img_array = np.expand_dims(img_array, axis=0)  # Adiciona dimensão extra (batch)
    img_array = preprocess_input(img_array)  # Pré-processamento específico da ResNet

    features = model.predict(img_array)  # Obtém os embeddings
    return features.flatten()  # Transforma em vetor 1D

# Processar todas as imagens das classes
for class_name in os.listdir(output_dir):
    class_path = os.path.join(output_dir, class_name)
    if os.path.isdir(class_path):
        embeddings[class_name] = {}

        for img_file in tqdm(os.listdir(class_path), desc=f"Processando {class_name}"):
            img_path = os.path.join(class_path, img_file)
            embeddings[class_name][img_file] = extract_features(img_path, resnet_model)

# Salvar embeddings para uso posterior
with open("fashion_embeddings.pkl", "wb") as f:
    pickle.dump(embeddings, f)

print("Extração de embeddings concluída e salva em 'fashion_embeddings.pkl'!")

# Construindo o modelo

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten

model = Sequential()
model.add(Flatten(input_shape=(2048,)))  # Assumindo que o ResNet50 gera features de 2048 dimensões
model.add(Dense(128, activation='relu'))
model.add(Dense(4, activation='softmax'))

# Compilando o modelo

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Treinando o modelo

from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical # Import to_categorical

# Carregando embeddings
with open("fashion_embeddings.pkl", "rb") as f:
    embeddings = pickle.load(f)

# Preparando features e labels
features = []
labels = []
for class_name, img_embeddings in embeddings.items():
    for img_file, feature_vector in img_embeddings.items():
        features.append(feature_vector)
        labels.append(class_name)

# Convertendo labels de string para numéricos usando LabelEncoder
label_encoder = LabelEncoder()
labels = label_encoder.fit_transform(labels)

# Convertendo features para NumPy array
features = np.array(features) # Convert features to NumPy array

# Dividindo os dados
X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)

# Convertendo labels para one-hot encoding usando to_categorical
y_train = to_categorical(y_train, num_classes=4) # Convert y_train
y_test = to_categorical(y_test, num_classes=4)   # Convert y_test

# Recriando o modelo antes do treinamento
# Isso garante que não haja variáveis criadas fora do escopo do tf.function
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten

model = Sequential()
model.add(Flatten(input_shape=(2048,)))  # Assumindo que o ResNet50 gera features de 2048 dimensões
model.add(Dense(128, activation='relu'))
model.add(Dense(4, activation='softmax'))

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Treinando o modelo
history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))

# Carregando os embeddings

import pickle

# Carregar os embeddings salvos
with open("fashion_embeddings.pkl", "rb") as f:
    data = pickle.load(f)

# Transformar os embeddings em um DataFrame para facilitar a manipulação
df_embeddings = pd.DataFrame(data)
print(df_embeddings.head())  # Ver os primeiros registros

# Transformando id da imagem em coluna (estava sendo utilizado como índice)

df_embeddings.reset_index(inplace=True)  # Transforma o índice em coluna
df_embeddings.rename(columns={"index": "id_image"}, inplace=True)  # Renomeia para evitar conflito
df_embeddings.head()

# Implementando função de similaridade por Distância Euclidiana

from scipy.spatial.distance import euclidean

def encontrar_similares(image_id, df_embeddings, top_n=5):

    # Filtrar a linha correspondente à imagem de referência
    image_row = df_embeddings[df_embeddings['id_image'] == image_id]

    # Encontrar a coluna que contém o embedding (onde não é NaN)
    embedding_column = image_row.drop(columns=['id_image']).dropna(axis=1).columns[0]

    # Pegar o embedding da imagem de referência
    target_embedding = image_row[embedding_column].values[0]

    # Calcular a distância entre a imagem-alvo e todas as outras imagens
    def calcular_distancia(row):
        emb_col = row.drop(labels=['id_image']).dropna().values[0]  # Pegar o embedding da linha
        return euclidean(target_embedding, emb_col)

    df_embeddings["distancia"] = df_embeddings.apply(calcular_distancia, axis=1)

    # Ordenar e pegar as top_n imagens mais similares
    similares = df_embeddings.sort_values(by="distancia")[1:top_n+1]  # Ignora a própria imagem (distância 0)

    return similares[["id_image", "distancia"]]

# Testando com uma imagem do dataset

image_id_teste = "16105.jpg"
resultados = encontrar_similares(image_id_teste, df_embeddings)
print(resultados)