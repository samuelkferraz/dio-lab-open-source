# -*- coding: utf-8 -*-
"""Bootcamp DIO - 4 - Detec√ß√£o com a Rede YOLO.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xQd49xu9_ai5scTXYcuhrmrdd0-dotbI

# Tarefa de Detec√ß√£o usando rede YOLO

O objetivo desse c√≥digo √©, atrav√©s de Transfer Learning, utilizar a rede YOLO em uma tarefa de detec√ß√£o de objetos a partir da inser√ß√£o de novas 2 novas classes extra√≠das de um dataset COCO.
"""

# Instalando pycocotools para manipular dataset do COCO
!pip install pycocotools

# Obtendo o dataset do COCO

# Anota√ß√µes
!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip

# Imagens
!wget http://images.cocodataset.org/zips/train2017.zip -P /content/coco/

# Descomprimindo os arquivos do COCO

# Extrair imagens de treino
!unzip /content/coco/train2017.zip -d /content/coco/

# Verificando salvamento correto do dataset

import os

train_images_path = "/content/coco/train2017"
annotations_path = "/content/coco/annotations"

if os.path.exists(train_images_path):
    print("‚úÖ A pasta 'train2017' foi criada com sucesso!")
else:
    print("‚ùå A pasta 'train2017' n√£o foi encontrada.")

# Verificando o dataset

import os

# Caminho das imagens de treino
train_images_path = "/content/coco/train2017"

# Listar as primeiras 5 imagens
image_files = os.listdir(train_images_path)[:5]
print("üìÇ Primeiras imagens encontradas:", image_files)

# Exibindo algumas imagens do dataset

import random
import matplotlib.pyplot as plt
import cv2

# Escolher uma imagem aleat√≥ria
random_image = random.choice(os.listdir(train_images_path))
image_path = os.path.join(train_images_path, random_image)

# Carregar e exibir a imagem
image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Converter para RGB

plt.imshow(image)
plt.axis("off")
plt.title(f"Exibindo: {random_image}")
plt.show()

# Importando e abrindo o arquivo de anota√ß√µes para detec√ß√£o

import json

# Extrair anota√ß√µes
!unzip /content/annotations_trainval2017.zip -d /content/coco/

# Caminho do arquivo de anota√ß√µes de treino
annotations_path = "/content/coco/annotations/instances_train2017.json"

# Carregar o JSON
with open(annotations_path, "r") as f:
    coco_data = json.load(f)

# Explorar as chaves principais do JSON
print("üîç Chaves principais do arquivo:", coco_data.keys())

# Visualizando algumas anota√ß√µes

# Ver as primeiras 3 anota√ß√µes
annotations = coco_data["annotations"][:3]
for ann in annotations:
    print(json.dumps(ann, indent=4))

# Escolhendo as 2 classes a serem utilizadas no desafio

# Ver as categorias dispon√≠veis no dataset
categories = coco_data["categories"]
for cat in categories:
    print(cat["id"], cat["name"])

# Pegar os IDs das classes de interesse
classes_interesse = ["bus", "train"]
class_ids = {cat["id"]: cat["name"] for cat in categories if cat["name"] in classes_interesse}

print("üöç Classes de interesse:", class_ids)

# Filtrando as classes de interesse (bus e train)

# Filtrar anota√ß√µes apenas de "bus" e "train"
filtered_annotations = [ann for ann in coco_data["annotations"] if ann["category_id"] in class_ids]

print(f"üîé Total de anota√ß√µes filtradas: {len(filtered_annotations)}")

# Conectando as anota√ß√µes filtradas com suas respectivas imagens

# Criar um dicion√°rio para mapear imagem_id -> nome do arquivo
image_id_to_filename = {img["id"]: img["file_name"] for img in coco_data["images"]}

# Criar um dicion√°rio para mapear imagem_id -> anota√ß√µes
image_annotations = {}

for ann in filtered_annotations:
    image_id = ann["image_id"]
    if image_id not in image_annotations:
        image_annotations[image_id] = []
    image_annotations[image_id].append(ann)

# Verificar quantas imagens possuem anota√ß√µes das classes de interesse
print(f"üì∏ Total de imagens com 'bus' e 'train': {len(image_annotations)}")

# Visualizando algumas imagens com bounding box

import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image

# Caminho para a pasta de imagens
image_folder = "/content/coco/train2017"

# Selecionar algumas imagens aleatoriamente
sample_image_ids = list(image_annotations.keys())[:5]  # Pegamos 5 imagens para visualizar

for image_id in sample_image_ids:
    image_path = f"{image_folder}/{image_id_to_filename[image_id]}"

    # Carregar imagem
    image = Image.open(image_path)

    # Criar figura
    fig, ax = plt.subplots(1, figsize=(8, 8))
    ax.imshow(image)

    # Adicionar bounding boxes
    for ann in image_annotations[image_id]:
        bbox = ann["bbox"]  # [x, y, largura, altura]
        x, y, w, h = bbox

        rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none')
        ax.add_patch(rect)

    plt.show()

# Convertendo o .json para .txt e normalizando as imagens

import os

# Criar diret√≥rio para os r√≥tulos (labels)
yolo_labels_dir = "/content/coco/yolo_labels"
os.makedirs(yolo_labels_dir, exist_ok=True)

# Criar arquivos YOLO para cada imagem
for image_id, annotations in image_annotations.items():
    img_filename = image_id_to_filename[image_id]
    txt_filename = os.path.join(yolo_labels_dir, img_filename.replace(".jpg", ".txt"))

    with open(txt_filename, "w") as yolo_file:
        for ann in annotations:
            # Pegar a categoria e converter para √≠ndice (YOLO exige √≠ndices come√ßando de 0)
            class_id = list(class_ids.keys()).index(ann["category_id"])

            # Pegar resolu√ß√£o da imagem correspondente (important√≠ssimo para normalizar)
            img_info = next(img for img in coco_data["images"] if img["id"] == image_id)
            img_width = img_info["width"]
            img_height = img_info["height"]

            # Pegar bounding box (COCO: [x_min, y_min, largura, altura])
            x, y, w, h = ann["bbox"]

            # Normalizar valores para o formato YOLO
            x_center = (x + w / 2) / img_width
            y_center = (y + h / 2) / img_height
            w /= img_width
            h /= img_height

            # Escrever no arquivo
            yolo_file.write(f"{class_id} {x_center} {y_center} {w} {h}\n")

print(f"‚úÖ Arquivos YOLO salvos em: {yolo_labels_dir}")

# Verificando a cria√ß√£o dos arquivos .txt

# Ver os primeiros arquivos gerados
txt_files = os.listdir(yolo_labels_dir)[:5]
print("üìÇ Arquivos YOLO gerados:", txt_files)

# Mostrar o conte√∫do de um arquivo de exemplo
if txt_files:
    with open(os.path.join(yolo_labels_dir, txt_files[0]), "r") as f:
        print(f"\nüìÑ Conte√∫do de {txt_files[0]}:\n")
        print(f.read())

# Criar os diret√≥rios para treinamento da rede

import os

# Diret√≥rio principal para o dataset YOLO
yolo_dataset_path = "/content/coco/yolo_dataset"
os.makedirs(yolo_dataset_path, exist_ok=True)

# Criar subpastas para imagens e labels de treino e valida√ß√£o
for folder in ["images/train", "images/val", "labels/train", "labels/val"]:
    os.makedirs(os.path.join(yolo_dataset_path, folder), exist_ok=True)

print("‚úÖ Estrutura de diret√≥rios criada!")

# Separando dados de treino e de teste (70/30)

import random
import shutil

# Definir a porcentagem de treino
train_ratio = 0.7

# Obter IDs das imagens e embaralhar
image_ids = list(image_annotations.keys())
random.shuffle(image_ids)

# Separar os IDs para treino e valida√ß√£o
split_idx = int(len(image_ids) * train_ratio)
train_ids = image_ids[:split_idx]
val_ids = image_ids[split_idx:]

print(f"üìÇ {len(train_ids)} imagens para treino, {len(val_ids)} imagens para valida√ß√£o.")

# Fun√ß√£o para mover arquivos
def move_files(image_set, subset):
    for image_id in image_set:
        img_filename = image_id_to_filename[image_id]
        txt_filename = img_filename.replace(".jpg", ".txt")

        # Caminhos origem/destino
        img_src = f"/content/coco/train2017/{img_filename}"
        txt_src = f"/content/coco/yolo_labels/{txt_filename}"

        img_dst = f"{yolo_dataset_path}/images/{subset}/{img_filename}"
        txt_dst = f"{yolo_dataset_path}/labels/{subset}/{txt_filename}"

        # Copiar arquivos
        shutil.copy(img_src, img_dst)
        shutil.copy(txt_src, txt_dst)

# Mover arquivos de treino e valida√ß√£o
move_files(train_ids, "train")
move_files(val_ids, "val")

print("‚úÖ Imagens e labels organizadas!")

# Gerando os arquivos de configura√ß√£o do YOLO

# Criar obj.names
with open(f"{yolo_dataset_path}/obj.names", "w") as f:
    for class_name in class_ids.values():
        f.write(f"{class_name}\n")

# Criar obj.data
obj_data = f"""classes = {len(class_ids)}
train = {yolo_dataset_path}/train.txt
valid = {yolo_dataset_path}/val.txt
names = {yolo_dataset_path}/obj.names
backup = /content/backup/
"""

with open(f"{yolo_dataset_path}/obj.data", "w") as f:
    f.write(obj_data)

# Criar train.txt e val.txt com os caminhos das imagens
def create_txt_file(image_set, filename):
    with open(f"{yolo_dataset_path}/{filename}", "w") as f:
        for image_id in image_set:
            img_filename = image_id_to_filename[image_id]
            f.write(f"{yolo_dataset_path}/images/{'train' if filename == 'train.txt' else 'val'}/{img_filename}\n")

create_txt_file(train_ids, "train.txt")
create_txt_file(val_ids, "val.txt")

print("‚úÖ Arquivos de configura√ß√£o criados!")

# Commented out IPython magic to ensure Python compatibility.
# Clonando e compilando o Darknet (framework que roda o YOLO)

# Clonar o reposit√≥rio do Darknet
!git clone https://github.com/AlexeyAB/darknet.git /content/darknet

# Entrar no diret√≥rio do Darknet
# %cd /content/darknet

# Editar Makefile para ativar GPU e OpenCV
!sed -i 's/GPU=0/GPU=1/' Makefile
!sed -i 's/CUDNN=0/CUDNN=1/' Makefile
!sed -i 's/OPENCV=0/OPENCV=1/' Makefile

# Compilar o Darknet
!make

# Configurando o yolov4.config para o novo dataset

# Criar uma c√≥pia do arquivo original para edi√ß√£o
!cp /content/darknet/cfg/yolov4-custom.cfg /content/darknet/cfg/yolov4.cfg

# Modificar par√¢metros no arquivo .cfg
!sed -i 's/batch=64/batch=32/' /content/darknet/cfg/yolov4.cfg
!sed -i 's/subdivisions=16/subdivisions=16/' /content/darknet/cfg/yolov4.cfg
!sed -i 's/max_batches = 500500/max_batches = 4000/' /content/darknet/cfg/yolov4.cfg
!sed -i 's/steps=400000,450000/steps=3200,3600/' /content/darknet/cfg/yolov4.cfg


# Alterar a quantidade de classes (2 para "bus" e "train")
!sed -i 's/classes=80/classes=2/' /content/darknet/cfg/yolov4.cfg

# Alterar os filtros antes de cada camada YOLO (filters = (classes + 5) * 3 ‚Üí (2 + 5) * 3 = 21)
!sed -i 's/filters=255/filters=21/' /content/darknet/cfg/yolov4.cfg

# Baixando os pesos pr√©-treinados do YOLO

!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4.conv.137

# Iniciando o treinamento da rede com as novas classes

!./darknet detector train /content/coco/yolo_dataset/obj.data \
                         cfg/yolov4.cfg yolov4.conv.137 \
                         -dont_show -map

# Inserindo uma nova imagem para testar a rede treinada

!cp /content/teste-img.jpg /content/darknet/data/teste-img.jpg

# Testando a rede treinada

!./darknet detector test /content/coco/yolo_dataset/obj.data cfg/yolov4.cfg \
                         backup/yolov4_last.weights data/test.jpg -thresh 0.3