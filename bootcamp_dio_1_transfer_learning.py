# -*- coding: utf-8 -*-
"""Bootcamp DIO // 1. Transfer Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_5DNRN8X3B7odmmuqdg4CF-jbiDMEs97
"""

#Baixando do Kaggle uma base de dados de imagens de minerais, que serão objeto desse Transfer Learning.

import kagglehub

# Download latest version
path = kagglehub.dataset_download("asiedubrempong/minerals-identification-dataset")

print("Path to dataset files:", path)

# Commented out IPython magic to ensure Python compatibility.
#Importando as bibliotecas a serem utilizadas para o Transfer Learning

# %matplotlib inline

import os

#if using Theano with GPU
#os.environ["KERAS_BACKEND"] = "tensorflow"

import random
import numpy as np
import keras

import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow

from keras.preprocessing import image
from keras.applications.imagenet_utils import preprocess_input
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Activation
from keras.layers import Conv2D, MaxPooling2D
from keras.models import Model

# Importando para o dataset apenas as classes a serem utilizadas (pyrite e quartz)

import os

# Diretório raiz do dataset
root = '/root/.cache/kagglehub/datasets/asiedubrempong/minerals-identification-dataset/versions/1/minet'
exclude = ['biotite', 'bornite', 'chrysocolla', 'malachite', 'muscovite']
train_split, val_split = 0.7, 0.15

# Listar todas as subpastas do diretório raiz
categories = [os.path.join(root, folder) for folder in os.listdir(root) if os.path.isdir(os.path.join(root, folder))]

# Filtrar as categorias para excluir as indesejadas (usando o caminho completo)
categories = [c for c in categories if os.path.basename(c) not in exclude]

print("Categorias finais para inclusão no dataset:")
print(categories)

# Função auxiliar para ajustar tamanho, vetorizar e pré-processar as imagens como input para o modelo.

def get_image(path):
    img = image.load_img(path, target_size=(224, 224))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)
    return img, x

# Carregando todas as imagens da pasta para o dataset

data = []
for c, category in enumerate(categories):
    images = [os.path.join(dp, f) for dp, dn, filenames
              in os.walk(category) for f in filenames
              if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]
    for img_path in images:
        img, x = get_image(img_path)
        data.append({'x':np.array(x[0]), 'y':c})

# Contando o número de classes
num_classes = len(categories)
print(num_classes)

# Randomizando a ordem dos dados

random.shuffle(data)

# Criando o corte de treino (70%), validação (15%) e teste (15%)

idx_val = int(train_split * len(data))
idx_test = int((train_split + val_split) * len(data))
train = data[:idx_val]
val = data[idx_val:idx_test]
test = data[idx_test:]

# Separando dados por rótulos

x_train, y_train = np.array([t["x"] for t in train]), [t["y"] for t in train]
x_val, y_val = np.array([t["x"] for t in val]), [t["y"] for t in val]
x_test, y_test = np.array([t["x"] for t in test]), [t["y"] for t in test]
print(y_test)

# Pré-processando garantindo normalização dos dados e formato float32

# normalize data
x_train = x_train.astype('float32') / 255.
x_val = x_val.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.

# convert labels to one-hot vectors
y_train = keras.utils.to_categorical(y_train, num_classes)
y_val = keras.utils.to_categorical(y_val, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)
print(y_test.shape)

# Resumo do que foi construído até então:
print("finished loading %d images from %d categories"%(len(data), num_classes))
print("train / validation / test split: %d, %d, %d"%(len(x_train), len(x_val), len(x_test)))
print("training data shape: ", x_train.shape)
print("training labels shape: ", y_train.shape)

# Visualizando algumas amostras do dataset

images = [os.path.join(dp, f) for dp, dn, filenames in os.walk(root) for f in filenames if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]
idx = [int(len(images) * random.random()) for i in range(8)]
imgs = [image.load_img(images[i], target_size=(224, 224)) for i in idx]
concat_image = np.concatenate([np.asarray(img) for img in imgs], axis=1)
plt.figure(figsize=(16,4))
plt.imshow(concat_image)

"""# **Treinando uma Rede Neural do zero**

Antes de executar o Transfer Learning, será treinada uma Rede Neural do zero com os dados desse dataset para estabelecer uma linha de base como parâmetro de comparação com desempenho obtido com Transfer Learning.

> Adicionar aspas



"""

# Construindo a rede do zero

model = Sequential()
print("Input dimensions: ",x_train.shape[1:])

model.add(Conv2D(32, (3, 3), input_shape=x_train.shape[1:]))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Dropout(0.25))

model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(256))
model.add(Activation('relu'))

model.add(Dropout(0.5))

model.add(Dense(num_classes))
model.add(Activation('softmax'))

model.summary()

# Compilando o modelo para usar funções Cross-Entropy Loss (Ajustar pesos pela diferença entre prob. prevista e real) e Adadelta (otimiza a convergência ajustado pesos para focar em gradientes maiores)

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

history = model.fit(x_train, y_train,
                    batch_size=128,
                    epochs=10,
                    validation_data=(x_val, y_val))

# Plotando curvas de perda e acurácia da validação

fig = plt.figure(figsize=(16,4))
ax = fig.add_subplot(121)
ax.plot(history.history["val_loss"])
ax.set_title("validation loss")
ax.set_xlabel("epochs")

ax2 = fig.add_subplot(122)
ax2.plot(history.history["val_accuracy"])
ax2.set_title("validation accuracy")
ax2.set_xlabel("epochs")
ax2.set_ylim(0, 1)

plt.show()

# Avaliando perda e acurácia rodando também os dados de treinamento no modelo

loss, accuracy = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', loss)
print('Test accuracy:', accuracy)

"""# **Aplicando Transfer Learning a uma rede existente**

Agora será executado o Transfer Learning, será treinada uma Rede Neural já existente com o dataset pequeno escolhido. Será utilizada VGG16 do Keras treinada no ImageNet. Na prática, o processo vai substituir uma das camadas finais por uma nova camada relacionada ao dataset aplicado.

"""

# Baixando VGG16 do Keras

vgg = keras.applications.VGG16(weights='imagenet', include_top=True)
vgg.summary()

# Referenciando a camada de input do VGG
inp = vgg.input

# Criando uma nova camada softmax layer com novo dataset
new_classification_layer = Dense(num_classes, activation='softmax')

# Conectando a nova camada às camadas do VGG
out = new_classification_layer(vgg.layers[-2].output)

# Criando uma nova rede entre input e output
model_new = Model(inp, out)

# Congelando os pesos e vieses das camadas mantidas originais, para que haja modificação no treinamento apenas para as camadas alteradas

# Desabilitando treinamento das camadas pelo congelamento de pesos (exceto para camada final)
for l, layer in enumerate(model_new.layers[:-1]):
    layer.trainable = False

# Garantindo o não congelamento da última camada
for l, layer in enumerate(model_new.layers[-1:]):
    layer.trainable = True

model_new.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

model_new.summary()

# Treinando o novo modelo

history2 = model_new.fit(x_train, y_train,
                         batch_size=128,
                         epochs=10,
                         validation_data=(x_val, y_val))

# Plotando curvas de perda e acurácia da validação comparando os dois métodos

fig = plt.figure(figsize=(16,4))
ax = fig.add_subplot(121)
ax.plot(history.history["val_loss"])
ax.plot(history2.history["val_loss"])
ax.set_title("validation loss")
ax.set_xlabel("epochs")

ax2 = fig.add_subplot(122)
ax2.plot(history.history["val_accuracy"])
ax2.plot(history2.history["val_accuracy"])
ax2.set_title("validation accuracy")
ax2.set_xlabel("epochs")
ax2.set_ylim(0, 1)

plt.show()

# Avaliando perda e acurácia rodando também os dados de treinamento no modelo

loss, accuracy = model_new.evaluate(x_test, y_test, verbose=0)

print('Test loss:', loss)
print('Test accuracy:', accuracy)

# Para predição de uma nova imagem, simplesmente rode o código para obter as probabilidades para cada classe.

!pip install requests

import requests
from io import BytesIO

# Update the get_image function
def get_image(path):
    """
    Loads an image from a path or URL.

    If the path is a URL, it will be downloaded first.
    """
    if path.startswith('https://images.ecycle.com.br/wp-content/uploads/2021/08/23154254/pyrite-626549_1920.jpg.webp'):  # Check if the path is a URL
        response = requests.get(path)
        response.raise_for_status()  # Raise an exception for bad responses
        img = image.load_img(BytesIO(response.content), target_size=(224, 224))
    else:
        img = image.load_img(path, target_size=(224, 224))

    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)
    return img, x

probabilities = model_new.predict([x])
print(categories, probabilities)