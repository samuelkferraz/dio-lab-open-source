# -*- coding: utf-8 -*-
"""Bootcamp DIO // 3. Métricas de Desempenho.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15dXcBY3h7IBOEUxv0ZVJh3MYFTO9Ax30

# Métricas de desempenho

A partir de uma matriz de confusão, o objetivo desse código é executar os cálculos das principais métricas de avaliação de um modelo de ML. A partir do VP, VN, FP, e FN serão obtidas acurácia, precisão, sensibilidade, especificidade, F1-Score e Curva ROC.
"""

!pip install --force-reinstall tensorflow-gpu

from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
import seaborn as sns
import pandas as pd

tf.__version__

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Diretório do TensorBoard
logdir='log'

# Incorporando MNIST, dividindo dados de treino e teste, normalização e definição das classes

(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()

train_images = train_images.reshape((60000, 28, 28,1))
test_images = test_images.reshape((10000, 28, 28,1))

train_images, test_images = train_images / 255.0, test_images / 255.0

classes=[0,1,2,3,4,5,6,7,8,9]

# Adicionando o modelo

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))

# Criando a callback do TensorBoard
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)

# Compilado e treinando o modelo
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x=train_images,
          y=train_labels,
          epochs = 5,
          validation_data=(test_images, test_labels))

y_true = test_labels
y_pred = np.argmax(model.predict(test_images), axis=-1)

classes=[0,1,2,3,4,5,6,7,8,9]

# Criando o dataset da Matriz de Confusão

con_mat = tf.math.confusion_matrix(labels=y_true, predictions=y_pred).numpy()
con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)

con_mat_df = pd.DataFrame(con_mat_norm,
                          index = classes,
                          columns = classes)

# Plotando a Matriz de Confusão

figure = plt.figure(figsize=(8, 8))
sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)
plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()

# Extraíndo as variáveis da Matriz de Confusão (VP, VN, FP, FN)

VP, FP, FN, VN = [], [], [], []

for i in range(len(classes)):
    vp = con_mat[i, i]  # Verdadeiro Positivo (diagonal principal)
    fp = np.sum(con_mat[:, i]) - vp  # Falso Positivo (soma da coluna menos VP)
    fn = np.sum(con_mat[i, :]) - vp  # Falso Negativo (soma da linha menos VP)
    vn = np.sum(con_mat) - (vp + fp + fn)  # Verdadeiro Negativo (restante da matriz)

    VP.append(vp)
    FP.append(fp)
    FN.append(fn)
    VN.append(vn)

# Converter listas para arrays NumPy (facilita operações vetorizadas)
VP, FP, FN, VN = np.array(VP), np.array(FP), np.array(FN), np.array(VN)

# Exibir os valores para cada classe
for i in range(len(classes)):
    print(f"Classe {classes[i]}: VP={VP[i]}, FP={FP[i]}, FN={FN[i]}, VN={VN[i]}")

# Calculando as métricas a partir das variáveis extraídas
accuracy = np.sum(VP + VN) / np.sum(VP + VN + FP + FN)
precision = VP / (VP + FP)
recall = VP / (VP + FN) # Sensibilidade
specificity = VN / (VN + FP)
f1_score = 2 * (precision * recall) / (precision + recall)

# Exibindo as métricas
print(f"Acurácia: {accuracy:.4f}")
print(f"Precisão por classe: {precision}")
print(f"Precisão média: {np.mean(precision):.4f}")
print(f"Sensibilidade por classe: {recall}")
print(f"Sensibilidade média: {np.mean(recall):.4f}")
print(f"Especificidade por classe: {specificity}")
print(f"Especificidade média: {np.mean(specificity):.4f}")
print(f"F1-Score por classe: {f1_score}")
print(f"F1-Score médio: {np.mean(f1_score):.4f}")

# Curva ROC e AUC utilizando Scikit-Learn

from sklearn.metrics import roc_curve, auc

# Criar as curvas ROC para cada classe (binária)
for i in range(len(classes)):
    fpr, tpr, _ = roc_curve(y_true == i, y_pred == i)  # Calcula os pontos da ROC
    roc_auc = auc(fpr, tpr)  # Área sob a curva

    plt.plot(fpr, tpr, label=f'Classe {classes[i]} (AUC = {roc_auc:.2f})')

# Plot final
plt.plot([0, 1], [0, 1], 'k--')  # Linha aleatória (AUC = 0.5)
plt.xlabel("Falsos Positivos (FPR)")
plt.ylabel("Verdadeiros Positivos (TPR)")
plt.title("Curva ROC por classe")
plt.legend()
plt.show()